import pandas as pd
import streamlit as st
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import RSLPStemmer
import os
import seaborn as sns
import matplotlib.pyplot as plt

# --- CONFIGURA√á√ÉO DA P√ÅGINA ---
st.set_page_config(
    page_title="Detector de Fake News",
    page_icon="üì∞",
    layout="wide",
)

# --- FUN√á√ïES AUXILIARES ---

# Baixar recursos necess√°rios do NLTK (apenas na primeira vez)
@st.cache_resource
def download_nltk_resources():
    try:
        stopwords.words('english')
    except LookupError:
        nltk.download('stopwords')
    try:
        nltk.data.find('stemmers/rslp')
    except LookupError:
        nltk.download('rslp')

download_nltk_resources()

def preprocess(text):
    text = str(text).lower()
    text = re.sub(r'[^a-z√°√†√¢√£√©√®√™√≠√Ø√≥√¥√µ√∂√∫√ß√± ]', '', text)
    tokens = text.split()
    stop_words = set(stopwords.words('english'))
    stemmer = RSLPStemmer()
    processed_tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]
    return ' '.join(processed_tokens)

def plot_confusion_matrix(cm, classes):
    fig, ax = plt.subplots(figsize=(5, 4))
    sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap='Blues', 
                xticklabels=classes, yticklabels=classes,
                annot_kws={"size": 14})
    ax.set_xlabel('R√≥tulo Previsto', fontsize=12)
    ax.set_ylabel('R√≥tulo Verdadeiro', fontsize=12)
    ax.tick_params(axis='both', which='major', labelsize=12)
    plt.setp(ax.get_yticklabels(), rotation=0)
    st.pyplot(fig, use_container_width=True)

# --- FUN√á√ÉO DE TREINAMENTO EM CACHE ---
@st.cache_data
def treinar_modelo_com_dados(df):
    if 'title' in df.columns and 'real' in df.columns:
        df['titulo_processado'] = df['title'].apply(preprocess)
        
        vectorizer = TfidfVectorizer(max_features=5000)
        X = vectorizer.fit_transform(df['titulo_processado'])
        y = df['real']
        
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        model = LogisticRegression(max_iter=1000)
        model.fit(X_train, y_train)
        
        return model, vectorizer, X_test, y_test
    else:
        st.error("O arquivo CSV carregado n√£o cont√©m as colunas necess√°rias ('title', 'real').")
        return None, None, None, None

# --- LAYOUT DA APLICA√á√ÉO ---

st.title("üì∞ Detector de Fake News Din√¢mico üì∞")
st.markdown("Fa√ßa o upload de um arquivo CSV para treinar um modelo de Machine Learning e come√ßar a classificar not√≠cias.")

# --- BARRA LATERAL PARA UPLOAD ---
with st.sidebar:
    st.header("1. Carregue seus Dados")
    uploaded_file = st.file_uploader(
        "Escolha um arquivo CSV",
        type="csv",
        help="O arquivo CSV deve conter as colunas 'title' (t√≠tulo da not√≠cia) e 'real' (1 para real, 0 para fake)."
    )

# --- L√ìGICA PRINCIPAL ---
if uploaded_file is not None:
    try:
        # Tenta ler com diferentes encodings
        try:
            dataframe = pd.read_csv(uploaded_file, sep=';')
        except UnicodeDecodeError:
            uploaded_file.seek(0) # Retorna ao in√≠cio do arquivo
            dataframe = pd.read_csv(uploaded_file, sep=';', encoding='latin1')
        
        st.sidebar.success("Arquivo carregado com sucesso!")
        st.sidebar.write("Amostra dos dados:")
        # --- ALTERA√á√ÉO AQUI ---
        # Removido o .head() para mostrar o DataFrame completo
        st.sidebar.dataframe(dataframe)

        model, vectorizer, X_test, y_test = treinar_modelo_com_dados(dataframe)

        if model:
            main_col1, main_col2 = st.columns([2, 3]) # Divide a tela em duas colunas

            with main_col1:
                st.subheader("2. Classifique uma nova not√≠cia")
                nova_noticia = st.text_area(
                    "Digite o t√≠tulo da not√≠cia:", 
                    height=150, 
                    placeholder="Ex: 'Cientistas descobrem a cura para...'"
                )
                
                if st.button("Analisar Not√≠cia", type="primary", use_container_width=True):
                    if nova_noticia:
                        texto_proc = preprocess(nova_noticia)
                        predicao = model.predict(vectorizer.transform([texto_proc]))
                        
                        if str(predicao[0]) == "1":
                            st.success("‚úÖ A not√≠cia parece ser: **Real**")
                        else:
                            st.error("‚ùå A not√≠cia parece ser: **Fake**")
                    else:
                        st.warning("Por favor, insira um t√≠tulo de not√≠cia para analisar.")

            with main_col2:
                st.subheader("3. Performance do Modelo")
                y_pred = model.predict(X_test)
                
                st.metric(label="Acur√°cia Geral do Modelo", value=f"{accuracy_score(y_test, y_pred):.2%}")
                
                with st.expander("üîç Ver detalhes da performance"):
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write("**Relat√≥rio de Classifica√ß√£o:**")
                        report = classification_report(y_test, y_pred, target_names=['Falsa', 'Real'], output_dict=True)
                        df_report = pd.DataFrame(report).transpose()
                        st.dataframe(df_report.round(2))
                    with col2:
                        st.write("**Matriz de Confus√£o:**")
                        cm = confusion_matrix(y_test, y_pred)
                        plot_confusion_matrix(cm, classes=['Falsa', 'Real'])

    except Exception as e:
        st.error(f"Ocorreu um erro ao processar o arquivo: {e}")

else:
    st.info("Aguardando o upload de um arquivo CSV para come√ßar.")